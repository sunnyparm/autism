# SSL ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
import os
import sys

# OpenSSL ì„¤ì • íŒŒì¼ ê²½ë¡œ ì§€ì •
script_dir = os.path.dirname(os.path.abspath(__file__))
openssl_conf_path = os.path.join(script_dir, 'openssl.cnf')

# OpenSSL ì„¤ì • ì ìš©
if os.path.exists(openssl_conf_path):
    os.environ['OPENSSL_CONF'] = openssl_conf_path
else:
    os.environ['OPENSSL_CONF'] = '/dev/null'

os.environ['PYTHONHTTPSVERIFY'] = '0'
os.environ['CURL_CA_BUNDLE'] = ''
os.environ['REQUESTS_CA_BUNDLE'] = ''

import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from urllib.parse import urljoin, urlparse, parse_qs
import re
import sqlite3
import urllib3
import ssl
from urllib3.poolmanager import PoolManager
from requests.adapters import HTTPAdapter
try:
    import chardet  # optional
except Exception:
    chardet = None

# --- í…”ë ˆê·¸ë¨ ì„¤ì • ---
# GitHub Actionsì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ, ë¡œì»¬ì—ì„œëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
TELEGRAM_BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN', '6250305411:AAHWIpJDIUU57x_cFORKGsPwecQq_QYlWmw')
TELEGRAM_CHAT_ID = int(os.environ.get('TELEGRAM_CHAT_ID', '752516623'))

# í…”ë ˆê·¸ë¨ ì„¤ì • í™•ì¸
def check_telegram_config():
    """í…”ë ˆê·¸ë¨ ì„¤ì •ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"""
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("âš ï¸  í…”ë ˆê·¸ë¨ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤!")
        print("1. í…”ë ˆê·¸ë¨ì—ì„œ @BotFatherì™€ ëŒ€í™”í•˜ì—¬ ë´‡ ìƒì„±")
        print("2. ë´‡ í† í°ê³¼ ì±„íŒ… IDë¥¼ ì½”ë“œì— ì„¤ì •")
        print("3. ìì„¸í•œ ë°©ë²•ì€ 'í…”ë ˆê·¸ë¨_ì„¤ì •_ê°€ì´ë“œ.md' íŒŒì¼ ì°¸ì¡°")
        return False
    print(f"âœ… í…”ë ˆê·¸ë¨ ì„¤ì • í™•ì¸ë¨ - ë´‡ í† í°: {TELEGRAM_BOT_TOKEN[:10]}..., ì±„íŒ… ID: {TELEGRAM_CHAT_ID}")
    return True

DB_PATH = 'autismnews.db'
TEST_MODE = False  # ì‹¤ì œ ëª¨ë“œ: í…”ë ˆê·¸ë¨ ì „ì†¡ í™œì„±í™”
DEBUG_LIST_ALL = True  # ë””ë²„ê·¸: ë‚ ì§œ í•„í„°ì™€ ë¬´ê´€í•˜ê²Œ ëª¨ë“  í–‰ì˜ ì œëª©/ì¼ìë¥¼ ì¶œë ¥
DAYS_WINDOW = 999999  # ëª¨ë“  ê¸°ì‚¬ ìˆ˜ì§‘ (ë‚ ì§œ ì œí•œ ì—†ìŒ)
HEADER_TITLE = 'í•œêµ­ìíì¸ì‚¬ë‘í˜‘íšŒ ê¸°ì‚¬'

def init_db():
    if TEST_MODE:
        return
    with sqlite3.connect(DB_PATH) as conn:
        cur = conn.cursor()
        cur.execute("""
            CREATE TABLE IF NOT EXISTS sent_news (
                title TEXT,
                date TEXT,
                PRIMARY KEY (title, date)
            )
        """)
        conn.commit()

def is_already_sent(title, date):
    # í…ŒìŠ¤íŠ¸ìš©: DB ê¸°ëŠ¥ ì¼ì‹œì •ì§€ - í•­ìƒ False ë°˜í™˜í•˜ì—¬ ëª¨ë“  ê¸°ì‚¬ ì „ì†¡
    return False

def save_sent(title, date):
    # í…ŒìŠ¤íŠ¸ìš©: DB ê¸°ëŠ¥ ì¼ì‹œì •ì§€ - ì €ì¥í•˜ì§€ ì•ŠìŒ
    pass

def send_telegram_message(message):
    """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë©”ì‹œì§€ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤."""
    if TEST_MODE:
        print("í…ŒìŠ¤íŠ¸ ëª¨ë“œ: í…”ë ˆê·¸ë¨ ì „ì†¡ ê±´ë„ˆëœ€")
        return False
        
    if not TELEGRAM_BOT_TOKEN or not TELEGRAM_CHAT_ID:
        print("í…”ë ˆê·¸ë¨ ë´‡ í† í° ë˜ëŠ” chat_idê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë©”ì‹œì§€ë¥¼ ì „ì†¡í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False
    
    try:
        # telepot ëŒ€ì‹  requestsë¥¼ ì‚¬ìš©í•˜ì—¬ í…”ë ˆê·¸ë¨ API ì§ì ‘ í˜¸ì¶œ
        url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
        
        # ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¸¸ë©´ ë¶„í• 
        max_length = 4096
        messages = [message[i:i+max_length] for i in range(0, len(message), max_length)]
        
        for msg_part in messages:
            if msg_part.strip():
                data = {
                    'chat_id': TELEGRAM_CHAT_ID,
                    'text': msg_part,
                    'parse_mode': 'HTML'
                }
                response = requests.post(url, data=data, timeout=10)
                if response.status_code != 200:
                    print(f"í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                    return False
        
        print("í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ.")
        return True
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

# ==============================
# ìˆ˜ì§‘ ëŒ€ìƒ URL (ì¹´í…Œê³ ë¦¬ë³„)
# ==============================
urls = [
    ('https://www.autismkorea.kr/bbs/board.php?tbl=bbs31', 'ê³µì§€ì‚¬í•­'),
    ('https://www.autismkorea.kr/bbs/board.php?tbl=bbs36', 'ë‰´ìŠ¤ë ˆí„°'),
    ('https://www.autismkorea.kr/bbs/board.php?tbl=bbs32', 'ì–¸ë¡ ë³´ë„'),
    ('https://www.autismkorea.kr/bbs/board.php?tbl=bbs34', 'ì™¸ë¶€ê¸°ê´€ ì†Œì‹')
]

# ë‹¤ì–‘í•œ User-Agent í’€
user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

def get_random_headers():
    """ëœë¤í•œ í—¤ë” ì¡°í•© ìƒì„±"""
    import random
    user_agent = random.choice(user_agents)
    
    base_headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Cache-Control': 'max-age=0'
    }
    
    # ëœë¤í•˜ê²Œ ì¶”ê°€ í—¤ë” ì„ íƒ
    if random.choice([True, False]):
        base_headers['DNT'] = '1'
    if random.choice([True, False]):
        base_headers['Sec-Fetch-Dest'] = 'document'
        base_headers['Sec-Fetch-Mode'] = 'navigate'
        base_headers['Sec-Fetch-Site'] = 'none'
    if random.choice([True, False]):
        base_headers['Referer'] = 'https://www.autismkorea.kr/'
    
    return base_headers

# SSL ê²€ì¦ ê²½ê³  ë¹„í™œì„±í™” (verify=False ì‚¬ìš© ì‹œ)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class TLSAdapter(HTTPAdapter):
    def init_poolmanager(self, *args, **kwargs):
        ctx = ssl.create_default_context()
        # SSL ê²€ì¦ ì™„ì „ ë¹„í™œì„±í™”
        ctx.check_hostname = False
        ctx.verify_mode = ssl.CERT_NONE
        
        # PythonAnywhere DH_KEY_TOO_SMALL ì˜¤ë¥˜ í•´ê²°
        try:
            # ë³´ì•ˆ ë ˆë²¨ì„ ìµœì†Œë¡œ ì„¤ì • + DH í‚¤ í—ˆìš©
            ctx.set_ciphers('DEFAULT:@SECLEVEL=0')
            # ë ˆê±°ì‹œ ì„œë²„ ì—°ê²° ì˜µì…˜ í™œì„±í™”
            ctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT
        except (ssl.SSLError, AttributeError):
            try:
                # ëŒ€ì²´ ë°©ë²•: ëª¨ë“  ì•”í˜¸í™” ë°©ì‹ í—ˆìš©
                ctx.set_ciphers('ALL:@SECLEVEL=0')
            except ssl.SSLError:
                try:
                    ctx.set_ciphers('ALL')
                except:
                    pass
        
        # í”„ë¡œí† ì½œ ë²„ì „ ì„¤ì • (ê°€ì¥ ë„“ì€ ë²”ìœ„)
        try:
            ctx.minimum_version = ssl.TLSVersion.TLSv1
            ctx.maximum_version = ssl.TLSVersion.TLSv1_3
            # TLS 1.0, 1.1 ëª…ì‹œì  í™œì„±í™”
            ctx.options &= ~ssl.OP_NO_TLSv1
            ctx.options &= ~ssl.OP_NO_TLSv1_1
        except AttributeError:
            # êµ¬ë²„ì „ Python í˜¸í™˜ì„±
            try:
                ctx.protocol = ssl.PROTOCOL_TLS
                ctx.options &= ~ssl.OP_NO_TLSv1
                ctx.options &= ~ssl.OP_NO_TLSv1_1
            except:
                pass
        
        # ì¶”ê°€ SSL ì˜µì…˜
        try:
            ctx.options |= ssl.OP_NO_COMPRESSION
        except:
            pass
        
        self.poolmanager = PoolManager(*args, ssl_context=ctx, **kwargs)

# ì—¬ëŸ¬ SSL ì„¤ì • ë°©ë²• ì‹œë„
def create_session_with_ssl_fallback():
    """SSL ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì—¬ëŸ¬ ë°©ë²•ì„ ì‹œë„í•˜ëŠ” ì„¸ì…˜ ìƒì„±"""
    
    # ë°©ë²• 1: ê°œì„ ëœ TLSAdapter ì‚¬ìš©
    try:
        session = requests.Session()
        session.mount('https://', TLSAdapter())
        return session
    except Exception as e:
        print(f"TLSAdapter ì‹¤íŒ¨: {e}")
    
    # ë°©ë²• 2: ê¸°ë³¸ ì„¸ì…˜ì— SSL ë¹„í™œì„±í™”
    try:
        session = requests.Session()
        session.verify = False
        return session
    except Exception as e:
        print(f"ê¸°ë³¸ ì„¸ì…˜ ì‹¤íŒ¨: {e}")
    
    # ë°©ë²• 3: urllib3 ì§ì ‘ ì‚¬ìš©
    try:
        import urllib3
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        session = requests.Session()
        session.verify = False
        return session
    except Exception as e:
        print(f"urllib3 ì„¸ì…˜ ì‹¤íŒ¨: {e}")
    
    # ìµœí›„ì˜ ìˆ˜ë‹¨: ê¸°ë³¸ requests
    return requests.Session()

session = create_session_with_ssl_fallback()

# í…ŒìŠ¤íŠ¸ìš©: ë‚ ì§œ ì œí•œ ì—†ì´ ëª¨ë“  ê¸°ì‚¬ ìˆ˜ì§‘
five_days_ago = datetime(1900, 1, 1)  # ë§¤ìš° ì˜¤ë˜ëœ ë‚ ì§œë¡œ ì„¤ì •í•˜ì—¬ ëª¨ë“  ê¸°ì‚¬ í¬í•¨
msg = ''
count = 1
debug_count = 1  # DEBUG_LIST_ALL ì¶œë ¥ìš© ìˆœë²ˆ

# í…”ë ˆê·¸ë¨ ì„¤ì • í™•ì¸
if not check_telegram_config():
    print("í…”ë ˆê·¸ë¨ ì„¤ì • í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    exit(1)

init_db()

def make_request_with_retry(url, max_retries=7):
    """403 ì˜¤ë¥˜ ë° SSL ì˜¤ë¥˜ë¥¼ í¬í•¨í•œ ê·¹ê°•í™”ëœ ì¬ì‹œë„ ë¡œì§"""
    import time
    import random
    
    # ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„± í•¨ìˆ˜ (SSL ìš°íšŒ)
    def create_custom_session():
        """SSL ì˜¤ë¥˜ ìš°íšŒë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ ì„¸ì…˜ ìƒì„±"""
        import urllib3
        from urllib3.util.ssl_ import create_urllib3_context
        
        class CustomHTTPAdapter(HTTPAdapter):
            def init_poolmanager(self, *args, **kwargs):
                context = create_urllib3_context()
                context.load_default_certs()
                context.check_hostname = False
                context.verify_mode = ssl.CERT_NONE
                
                # DH_KEY_TOO_SMALL ì˜¤ë¥˜ í•´ê²°
                try:
                    context.set_ciphers('DEFAULT:@SECLEVEL=0')
                    context.options |= 0x4  # OP_LEGACY_SERVER_CONNECT
                except:
                    try:
                        context.set_ciphers('ALL:@SECLEVEL=0')
                    except:
                        pass
                
                kwargs['ssl_context'] = context
                return super().init_poolmanager(*args, **kwargs)
        
        s = requests.Session()
        s.mount('https://', CustomHTTPAdapter())
        return s
    
    for attempt in range(max_retries):
        print(f"ìš”ì²­ ì‹œì‘ (ì‹œë„ {attempt + 1}/{max_retries}): {url}")
        
        try:
            # ë§¤ë²ˆ ëœë¤í•œ í—¤ë” ì‚¬ìš©
            current_headers = get_random_headers()
            
            # ì‹œë„ë³„ ë‹¤ë¥¸ ì „ëµ
            if attempt == 0:
                # ì²« ë²ˆì§¸ ì‹œë„: ê¸°ë³¸ ì„¸ì…˜ + ëœë¤ í—¤ë”
                res = session.get(url, headers=current_headers, timeout=25, verify=False)
            elif attempt == 1:
                # ë‘ ë²ˆì§¸ ì‹œë„: ì»¤ìŠ¤í…€ ì„¸ì…˜ (DH í‚¤ í•´ê²°)
                custom_session = create_custom_session()
                res = custom_session.get(url, headers=current_headers, timeout=25, verify=False)
                custom_session.close()
            elif attempt == 2:
                # ì„¸ ë²ˆì§¸ ì‹œë„: ìµœì†Œ í—¤ë” + ì»¤ìŠ¤í…€ ì„¸ì…˜
                minimal_headers = {'User-Agent': random.choice(user_agents)}
                custom_session = create_custom_session()
                res = custom_session.get(url, headers=minimal_headers, timeout=25, verify=False)
                custom_session.close()
            elif attempt == 3:
                # ë„¤ ë²ˆì§¸ ì‹œë„: ëª¨ë°”ì¼ User-Agent
                mobile_headers = {
                    'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
                }
                custom_session = create_custom_session()
                res = custom_session.get(url, headers=mobile_headers, timeout=25, verify=False)
                custom_session.close()
            elif attempt == 4:
                # ë‹¤ì„¯ ë²ˆì§¸ ì‹œë„: êµ¬í˜• ë¸Œë¼ìš°ì €
                old_headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'
                }
                res = requests.get(url, headers=old_headers, timeout=25, verify=False)
            elif attempt == 5:
                # ì—¬ì„¯ ë²ˆì§¸ ì‹œë„: curl ì‹œë®¬ë ˆì´ì…˜
                curl_headers = {
                    'User-Agent': 'curl/7.68.0',
                    'Accept': '*/*'
                }
                res = requests.get(url, headers=curl_headers, timeout=25, verify=False)
            else:
                # ì¼ê³± ë²ˆì§¸ ì‹œë„: ì™„ì „íˆ ë‹¤ë¥¸ ì ‘ê·¼
                res = requests.get(url, timeout=25, verify=False, allow_redirects=True)
            
            print(f"ìƒíƒœ ì½”ë“œ: {res.status_code}, ì‘ë‹µ ê¸¸ì´: {len(res.content)}")
            
            # 403 ì˜¤ë¥˜ ì²˜ë¦¬
            if res.status_code == 403:
                print(f"403 Forbidden ì˜¤ë¥˜ (ì‹œë„ {attempt + 1})")
                if attempt < max_retries - 1:
                    wait_time = random.uniform(3, 8) + attempt * 3  # ë” ê¸´ ëŒ€ê¸° ì‹œê°„
                    print(f"{wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    time.sleep(wait_time)
                    continue
                else:
                    print("ëª¨ë“  403 ì˜¤ë¥˜ ì¬ì‹œë„ ì‹¤íŒ¨")
                    return None
            
            # 200 ì„±ê³µ ì‹œ
            if res.status_code == 200:
                return res
            
            # ê¸°íƒ€ ìƒíƒœ ì½”ë“œ ì²˜ë¦¬
            if attempt < max_retries - 1:
                wait_time = random.uniform(2, 5)
                print(f"ìƒíƒœ ì½”ë“œ {res.status_code}ë¡œ ì¸í•œ {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
                continue
            
        except ssl.SSLError as e:
            print(f"SSL ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                wait_time = random.uniform(2, 5)
                print(f"SSL ì˜¤ë¥˜ë¡œ ì¸í•œ {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
                continue
            else:
                print("ëª¨ë“  SSL ì„¤ì • ì‹œë„ ì‹¤íŒ¨")
                return None
        except Exception as e:
            print(f"ìš”ì²­ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {e}")
            if attempt < max_retries - 1:
                wait_time = random.uniform(2, 6) + attempt
                print(f"ì˜¤ë¥˜ë¡œ ì¸í•œ {wait_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(wait_time)
                continue
            else:
                print("ëª¨ë“  ì‹œë„ ì‹¤íŒ¨")
                return None
    
    return None

# ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì‚¬ ìˆ˜ì§‘
categorized_articles = {}

for url, category in urls:
    print(f"\n=== {category} ìˆ˜ì§‘ ì¤‘ ===")
    res = make_request_with_retry(url)
    if res is None:
        continue
    
    # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    if category not in categorized_articles:
        categorized_articles[category] = []
    # ì‘ë‹µ ì¸ì½”ë”© íŒë³„: meta > headers > chardet > cp949 ë°±ì—…
    raw = res.content
    enc_candidates = []
    # meta charset ì¶”ì¶œ
    try:
        head_snippet = raw[:4096].decode('ascii', errors='ignore')
        m = re.search(r'charset=([\w\-]+)', head_snippet, re.IGNORECASE)
        if m:
            enc_candidates.append(m.group(1).lower())
    except Exception:
        pass
    if res.encoding:
        enc_candidates.append(res.encoding.lower())
    if chardet is not None:
        try:
            detected = chardet.detect(raw).get('encoding')
            if detected:
                enc_candidates.append(detected.lower())
        except Exception:
            pass
    # í•œêµ­ ì‚¬ì´íŠ¸ ì¼ë°˜ ë°±ì—… ì¸ì½”ë”©
    enc_candidates += ['utf-8', 'cp949', 'euc-kr']
    # í›„ë³´ ì¤‘ í•œê¸€ ê²€ì¶œë˜ëŠ” ì²« ë””ì½”ë”© ì‚¬ìš©
    selected = None
    for enc in enc_candidates:
        try:
            trial = raw.decode(enc, errors='replace')
            if re.search(r'[\uac00-\ud7a3]', trial):
                selected = enc
                html = trial
                break
        except Exception:
            continue
    if selected is None:
        # ë§ˆì§€ë§‰ ë°±ì—…
        html = raw.decode('utf-8', errors='replace')
    soup = BeautifulSoup(html, 'html.parser')

    # -----------------------------
    # (1) í•œêµ­ìíì¸ì‚¬ë‘í˜‘íšŒ ê³µì§€ì‚¬í•­
    # -----------------------------
    table = soup.find('table', class_='basic_board_list')
    if not table:
        # Fallback: ì¹´ë“œí˜• ëª©ë¡ (ul.horizontal_board > li)
        items = soup.select('ul.horizontal_board li')
        if not items:
            print("ëª©ë¡ í…Œì´ë¸”/ì¹´ë“œ ëª©ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            continue
        print(f"ì¹´ë“œí˜• ëª©ë¡ ê°œìˆ˜: {len(items)}")
        for li in items:
            a_tag = li.select_one('div.txt_box h4 a') or li.select_one('h4 a')
            if not a_tag:
                continue
            title = a_tag.get_text(strip=True)
            link = a_tag.get('href')
            full_url = urljoin(url, link)
            # VIEW ë§í¬ ì •ê·œí™”
            try:
                parsed = urlparse(full_url)
                qs = parse_qs(parsed.query)
                num = qs.get('num', [None])[0]
                tbl = qs.get('tbl', [''])[0]
                if num:
                    base = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
                    if not tbl:
                        # ì›ë³¸ URLì˜ tbl ìœ ì§€ ì‹œë„
                        orig_qs = parse_qs(urlparse(url).query)
                        tbl = orig_qs.get('tbl', [''])[0]
                    if tbl:
                        full_url = f"{base}?tbl={tbl}&mode=VIEW&num={num}"
            except Exception:
                pass

            # ë‚ ì§œ ì¶”ì¶œ: 'ì‘ì„±ì¼' ì£¼ë³€ ë˜ëŠ” YYYY-MM-DD íŒ¨í„´ ì°¾ê¸°
            date_key = None
            date_obj = None
            em = li.select_one('em')
            date_text = em.get_text(" ", strip=True) if em else li.get_text(" ", strip=True)
            m = re.search(r'(20\d{2}-\d{2}-\d{2})', date_text)
            if m:
                date_key = m.group(1)
                try:
                    y, mo, d = map(int, date_key.split('-'))
                    date_obj = datetime(y, mo, d)
                except Exception:
                    date_obj = None

            if not date_key or not date_obj:
                # ë‹¤ë¥¸ í¬ë§· ì‹œë„: YY.MM.DD
                m2 = re.search(r'(\d{2})\.(\d{2})\.(\d{2})', date_text)
                if m2:
                    y = int('20' + m2.group(1))
                    mo = int(m2.group(2))
                    d = int(m2.group(3))
                    try:
                        date_obj = datetime(y, mo, d)
                        date_key = date_obj.strftime('%Y-%m-%d')
                    except Exception:
                        date_key = None

            if not date_key:
                # ë‚ ì§œ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                continue

            if DEBUG_LIST_ALL:
                print(f"{debug_count}\t{title}\t{date_key}\t{full_url}")
                debug_count += 1

            # ìµœê·¼ 5ì¼ ì´ë‚´ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘
            if date_obj >= five_days_ago:
                if not is_already_sent(title, date_key):
                    article_info = {
                        'title': title,
                        'date': date_key,
                        'url': full_url
                    }
                    categorized_articles[category].append(article_info)
                    print(f"{len(categorized_articles[category])}. {title} ({date_key})")
                    save_sent(title, date_key)
        # ì¹´ë“œí˜•ì„ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ í…Œì´ë¸” íŒŒì‹±ì€ ê±´ë„ˆëœ€
        continue
    rows = table.find_all('tr')

    print(f"í–‰ ê°œìˆ˜: {len(rows)}")
    for row in rows:
        td_left = row.find('td', class_='left')
        if not td_left:
            continue

        a_tag = td_left.find('a')
        if not a_tag:
            continue

        title = a_tag.text.strip()
        link = a_tag.get('href')
        full_url = urljoin(url, link)
        # ê¹”ë”í•œ VIEW ë§í¬ë¡œ ì •ê·œí™”: ...&mode=VIEW&num=XXXX
        try:
            parsed = urlparse(full_url)
            qs = parse_qs(parsed.query)
            num = qs.get('num', [None])[0]
            tbl = qs.get('tbl', ['bbs31'])[0]
            if num:
                base = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
                full_url = f"{base}?tbl={tbl}&mode=VIEW&num={num}"
        except Exception:
            pass

        # ë‚ ì§œëŠ” <span> ì¤‘ ë‘ ë²ˆì§¸ (ì˜ˆ: 25.09.11)
        spans = td_left.find_all('span')
        if len(spans) >= 2:
            date_str = spans[1].text.strip()
        else:
            date_str = None

        if not date_str:
            continue

        # ë‚ ì§œ í˜•ì‹ ë³€í™˜
        try:
            # '25.09.11' â†’ '2025-09-11'
            year = int('20' + date_str.split('.')[0])
            month = int(date_str.split('.')[1])
            day = int(date_str.split('.')[2])
            date_obj = datetime(year, month, day)
            date_key = date_obj.strftime('%Y-%m-%d')
        except Exception:
            continue

        if DEBUG_LIST_ALL:
            print(f"{debug_count}\t{title}\t{date_key}\t{full_url}")
            debug_count += 1

        # ìµœê·¼ 5ì¼ ì´ë‚´ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘
        if date_obj >= five_days_ago:
            if not is_already_sent(title, date_key):
                article_info = {
                    'title': title,
                    'date': date_key,
                    'url': full_url
                }
                categorized_articles[category].append(article_info)
                print(f"{len(categorized_articles[category])}. {title} ({date_key})")
                save_sent(title, date_key)

# ==============================
# ì¹´í…Œê³ ë¦¬ë³„ í…”ë ˆê·¸ë¨ ì „ì†¡
# ==============================
total_articles = sum(len(articles) for articles in categorized_articles.values())

if total_articles > 0:
    print(f"\n=== ì´ {total_articles}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ ì™„ë£Œ ===")
    
    for category, articles in categorized_articles.items():
        if not articles:
            continue
            
        print(f"\n--- {category} ({len(articles)}ê°œ) ---")
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë©”ì‹œì§€ ìƒì„±
        category_message = f"<b>ğŸ“¢ {category}</b>\n\n"
        
        for i, article in enumerate(articles, 1):
            # HTML íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„
            title = article['title'].replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            article_text = f"<b>{i}.</b> {title}\nğŸ“… {article['date']}\nğŸ”— <a href='{article['url']}'>ë§í¬</a>\n\n"
            
            # ë©”ì‹œì§€ ê¸¸ì´ í™•ì¸ (4000ì ì œí•œ)
            if len(category_message + article_text) > 4000:
                # í˜„ì¬ ë©”ì‹œì§€ ì „ì†¡
                print(f"ì „ì†¡í•  ë©”ì‹œì§€ ({category}):\n{category_message}")
                if not TEST_MODE:
                    send_telegram_message(category_message)
                else:
                    print("í…ŒìŠ¤íŠ¸ ëª¨ë“œ: í…”ë ˆê·¸ë¨ ì „ì†¡ ê±´ë„ˆëœ€")
                
                # ìƒˆ ë©”ì‹œì§€ ì‹œì‘
                category_message = f"<b>ğŸ“¢ {category} (ê³„ì†)</b>\n\n" + article_text
            else:
                category_message += article_text
        
        # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì „ì†¡
        if category_message.strip():
            print(f"ì „ì†¡í•  ë©”ì‹œì§€ ({category}):\n{category_message}")
            if not TEST_MODE:
                send_telegram_message(category_message)
            else:
                print("í…ŒìŠ¤íŠ¸ ëª¨ë“œ: í…”ë ˆê·¸ë¨ ì „ì†¡ ê±´ë„ˆëœ€")
                
else:
    # ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ëŠ” ê²½ìš°
    no_news_message = f"<b>{HEADER_TITLE}</b>\n\nì‹ ê·œ ê³µì§€ì‚¬í•­ ì—†ìŒ"
    print(no_news_message)
    
    if not TEST_MODE:
        send_telegram_message(no_news_message)
    else:
        print("í…ŒìŠ¤íŠ¸ ëª¨ë“œ: í…”ë ˆê·¸ë¨ ì „ì†¡ ê±´ë„ˆëœ€")
